{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-t8BCmUKNuMb"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mew9xHnvzdXc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m----> 7\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\Guild-CpdTyoba\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2369\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2367\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2369\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2371\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2372\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\.virtualenvs\\Guild-CpdTyoba\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m backends_list)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[1;32m~\\.virtualenvs\\Guild-CpdTyoba\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3540\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable_matplotlib\u001b[39m(\u001b[38;5;28mself\u001b[39m, gui\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3520\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[0;32m   3521\u001b[0m \n\u001b[0;32m   3522\u001b[0m \u001b[38;5;124;03m    This takes the following steps:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3538\u001b[0m \u001b[38;5;124;03m        display figures inline.\u001b[39;00m\n\u001b[0;32m   3539\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3540\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_inline_support\n\u001b[0;32m   3542\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[0;32m   3543\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n",
      "File \u001b[1;32m~\\.virtualenvs\\Guild-CpdTyoba\\lib\\site-packages\\matplotlib_inline\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_inline, config  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.6\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\Guild-CpdTyoba\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colors\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_agg\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch.autograd import Variable\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2Bg56Nd0C21",
    "outputId": "0500a332-574e-4df5-b620-fcf4977ca412"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UozkbtMB0PQh"
   },
   "outputs": [],
   "source": [
    "def mnist_imshow(img):\n",
    "    plt.imshow(img.reshape([28,28]), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ir_1lR-lOK6u"
   },
   "outputs": [],
   "source": [
    "#@title Experiment Constants\n",
    "epochs = 2\n",
    "epochs = 50\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "sample_size = 200\n",
    "hidden_size = 200\n",
    "num_task = 3 # Number of tasks, task 1 we would not have any permutation\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPwKwrauAz2w"
   },
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIIODGl2239_"
   },
   "outputs": [],
   "source": [
    "class PermutedMNIST(datasets.MNIST):\n",
    "\n",
    "    def __init__(self, root=\"~/.torch/data/mnist\", train=True, permute_idx=None):\n",
    "        super(PermutedMNIST, self).__init__(root, train, download=True)\n",
    "        assert len(permute_idx) == 28 * 28\n",
    "        if self.train:\n",
    "          # print(\"data\", type(self.train_data),type(self.train_data[0]),self.train_data.shape, self.train_data[0].shape, self.train_data[0])\n",
    "          self.training_data= torch.stack([img.float().view(-1)[permute_idx] / 255 for img in self.train_data])\n",
    "          self.training_labels = self.train_labels\n",
    "        else:\n",
    "          self.testing_data = torch.stack([img.float().view(-1)[permute_idx] / 255 for img in self.test_data])\n",
    "          self.testing_labels = self.test_labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if self.train:\n",
    "            img, target = self.training_data[index], self.training_labels[index]\n",
    "        else:\n",
    "            img, target = self.testing_data[index], self.testing_labels[index]\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def get_sample(self, sample_size):\n",
    "        sample_idx = random.sample(range(len(self)), sample_size)\n",
    "        return [img for img in self.training_data[sample_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RmbGeB54SLO",
    "outputId": "d97b0ab0-d96d-401f-a16d-37feee7c719e"
   },
   "outputs": [],
   "source": [
    "def get_permute_mnist():\n",
    "    train_loader = {}\n",
    "    test_loader = {}\n",
    "    idx = list(range(28 * 28)) # first time there is no shuffle\n",
    "    for i in range(num_task):\n",
    "        train_loader[i] = torch.utils.data.DataLoader(PermutedMNIST(train=True, permute_idx=idx),\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      num_workers=4)\n",
    "        test_loader[i] = torch.utils.data.DataLoader(PermutedMNIST(train=False, permute_idx=idx),\n",
    "                                                     batch_size=batch_size)\n",
    "        print(f'Index for  task {i} \\n {idx}')\n",
    "        idx = random.sample(idx, len(idx))\n",
    "    return train_loader, test_loader \n",
    "\n",
    "\n",
    "train_loader, test_loader = get_permute_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "N9_VzEOe944D",
    "outputId": "b67b57f1-4663-4e17-ba2f-fc8dc23dcedc"
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "for i in range(num_task):\n",
    "  print(f' ------task {i} --------')\n",
    "  batch = next(iter(train_loader[i]))\n",
    "  if t == 0:\n",
    "    t = random.randint(1,len(batch))\n",
    "  image, label = batch[0][t], batch[1][t]\n",
    "  print (batch[0][t].shape)\n",
    "  print(\"label : \", label.item())  \n",
    "  mnist_imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fhd020tFBSjj"
   },
   "source": [
    "## Network\n",
    "A simple network with only Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11gMlQ_tATUi",
    "outputId": "ee7a1ec2-e2ae-4576-c237-47fc72da1f04"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_size=200):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.fc1(input))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "model = MLP().to(device)\n",
    "summary(model, input_size=(1,784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TyLrcpSCW5d"
   },
   "source": [
    "## Normal Train Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuPKHl4DD8X-"
   },
   "source": [
    "Variable Function - Used for Gradient [Reference](https://www.geeksforgeeks.org/variables-and-autograd-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZLeg4S-Cu0w"
   },
   "outputs": [],
   "source": [
    "def variable(t: torch.Tensor, use_cuda=True, **kwargs):\n",
    "  \"\"\"\n",
    "  Takes in a tensor and converts into a tensor with gradient\n",
    "  We would need gradients of parameters, hence needed \n",
    "  \"\"\"\n",
    "  if torch.cuda.is_available() and use_cuda:\n",
    "    t = t.cuda()\n",
    "  return Variable(t, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GC0xaEMDBhd9"
   },
   "outputs": [],
   "source": [
    "def normal_train(model: nn.Module, \n",
    "                 optimizer: torch.optim, \n",
    "                 data_loader: torch.utils.data.DataLoader):\n",
    "  \"\"\"\n",
    "  Takes in a model architecture, trains its and returns average epoch loss\n",
    "  \"\"\"\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "  for input, target in data_loader:\n",
    "      input, target = variable(input), variable(target)\n",
    "      optimizer.zero_grad()\n",
    "      output = model(input)\n",
    "      loss = F.cross_entropy(output, target)\n",
    "      epoch_loss += loss.item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyCWxxpHNl9W"
   },
   "source": [
    "## Normal Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmMNFbKPMwLl"
   },
   "outputs": [],
   "source": [
    "def test(model: nn.Module, \n",
    "         data_loader: torch.utils.data.DataLoader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for input, target in data_loader:\n",
    "        input, target = variable(input), variable(target)\n",
    "        output = model(input)\n",
    "        correct += (F.softmax(output, dim=1).max(dim=1)[1] == target).data.sum()\n",
    "    return correct / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prQlMMx8EvjZ"
   },
   "source": [
    "## Elastic Weight Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3AgaT_vB-1p"
   },
   "outputs": [],
   "source": [
    "class EWC(object):\n",
    "    def __init__(self, \n",
    "                 model: nn.Module, \n",
    "                 dataset: list):\n",
    "\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "\n",
    "        # default model params\n",
    "        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad}\n",
    "        self._means = {}\n",
    "        self._precision_matrices = self._diag_fisher()\n",
    "\n",
    "        for n, p in deepcopy(self.params).items():\n",
    "            self._means[n] = variable(p.data)\n",
    "\n",
    "    def _diag_fisher(self):\n",
    "        precision_matrices = {}\n",
    "        for n, p in deepcopy(self.params).items():\n",
    "            p.data.zero_()\n",
    "            precision_matrices[n] = variable(p.data)\n",
    "\n",
    "        self.model.eval() # we need to do one round of back propogation to understand the gradients of params\n",
    "        # interestingly we dont have to always use model.train() to get the gradients\n",
    "        for input in self.dataset:\n",
    "            self.model.zero_grad()\n",
    "            input = variable(input)\n",
    "            output = self.model(input).view(1, -1)\n",
    "            label = output.max(1)[1].view(-1)\n",
    "            loss = F.nll_loss(F.log_softmax(output, dim=1), label)\n",
    "            loss.backward()\n",
    "\n",
    "            for n, p in self.model.named_parameters():\n",
    "                precision_matrices[n].data += p.grad.data ** 2 / len(self.dataset)\n",
    "\n",
    "        precision_matrices = {n: p for n, p in precision_matrices.items()}\n",
    "        return precision_matrices\n",
    "\n",
    "    def penalty(self, model: nn.Module):\n",
    "        loss = 0\n",
    "        for n, p in model.named_parameters():\n",
    "            _loss = self._precision_matrices[n] * (p - self._means[n]) ** 2\n",
    "            loss += _loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoNJoihFMWYR"
   },
   "source": [
    "### EWC Train Function\n",
    "This has got Penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsxEkomJMS5c"
   },
   "outputs": [],
   "source": [
    "def ewc_train(model: nn.Module, \n",
    "              optimizer: torch.optim, \n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              ewc: EWC, \n",
    "              importance: float): # importance is a hyperparam \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for input, target in data_loader:\n",
    "        input, target = variable(input), variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        ##-------Updated Loss Function-------###\n",
    "        loss = F.cross_entropy(output, target) + importance * ewc.penalty(model)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwdRBH_URrSn"
   },
   "source": [
    "\n",
    "## Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ucr_DlDCRo_V"
   },
   "outputs": [],
   "source": [
    "def loss_plot(x):\n",
    "    for t, v in x.items():\n",
    "        plt.plot(list(range(t * epochs, (t + 1) * epochs)), v, label = \"Task \"+ str(t))\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.title(\"Loss Plot\")\n",
    "    plt.show()\n",
    "\n",
    "def accuracy_plot(x):\n",
    "    for t, v in x.items():\n",
    "        plt.plot(list(range(t * epochs, num_task * epochs)), v, label = \"Task \"+  str(t))\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.title(\"Accuracy Plot\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_khx8ERN1QN"
   },
   "source": [
    "## Standard Process Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSeexybANCk_"
   },
   "outputs": [],
   "source": [
    "def standard_process(epochs, use_cuda=True, weight=True):\n",
    "    model = MLP(hidden_size)\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        model.cuda()\n",
    "    optimizer = optim.SGD(params=model.parameters(), lr=lr)\n",
    "\n",
    "    loss, acc = {}, {} # across tasks \n",
    "    for task in range(num_task):\n",
    "        loss[task] = [] # per task loss\n",
    "        acc[task] = [] # per task accuracy\n",
    "        for _ in tqdm(range(epochs)):\n",
    "            loss[task].append(normal_train(model, optimizer, train_loader[task]))\n",
    "            for sub_task in range(task + 1):\n",
    "                acc[sub_task].append(test(model, test_loader[sub_task]))\n",
    "        if task == 0 and weight:\n",
    "            weight = model.state_dict()\n",
    "    return loss, acc, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmihHuWgO8Vd",
    "outputId": "332fba51-0e2d-42f3-a38f-86b10120018a"
   },
   "outputs": [],
   "source": [
    "#@title Training and Output of Standard Process\n",
    "loss, acc, weight = standard_process(epochs) # The weights are used by EWC process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "Ve29OTX-TQCd",
    "outputId": "b09941db-65bc-4591-c916-415bdc21953a"
   },
   "outputs": [],
   "source": [
    "loss_plot(loss), accuracy_plot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGBtf4g0SX2Z",
    "outputId": "9ddcc5a7-c0dc-41ec-f5d8-03158c031cfc"
   },
   "outputs": [],
   "source": [
    "(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YzC2LnRR9IB"
   },
   "source": [
    "## EWC Process Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUCy9Cd7PXV1"
   },
   "outputs": [],
   "source": [
    "def ewc_process(epochs, importance, use_cuda=True, weight=None):\n",
    "    model = MLP(hidden_size)\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        model.cuda()\n",
    "    optimizer = optim.SGD(params=model.parameters(), lr=lr)\n",
    "\n",
    "    loss, acc, ewc = {}, {}, {}\n",
    "    for task in range(num_task):\n",
    "        loss[task] = []\n",
    "        acc[task] = []\n",
    "\n",
    "        if task == 0:\n",
    "            if weight:\n",
    "                model.load_state_dict(weight)\n",
    "            else:\n",
    "                for _ in tqdm(range(epochs)):\n",
    "                    loss[task].append(normal_train(model, optimizer, train_loader[task]))\n",
    "                    acc[task].append(test(model, test_loader[task]))\n",
    "        else:\n",
    "            old_tasks = []\n",
    "            for sub_task in range(task):\n",
    "                old_tasks = old_tasks + train_loader[sub_task].dataset.get_sample(sample_size)\n",
    "            old_tasks = random.sample(old_tasks, k=sample_size)\n",
    "            for _ in tqdm(range(epochs)):\n",
    "                loss[task].append(ewc_train(model, optimizer, train_loader[task], EWC(model, old_tasks), importance))\n",
    "                for sub_task in range(task + 1):\n",
    "                    acc[sub_task].append(test(model, test_loader[sub_task]))\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xL-C07MGTpQM",
    "outputId": "1c403797-b41d-4d8d-de86-c2d0839ad588"
   },
   "outputs": [],
   "source": [
    "#@title Training and Output of EWC Process\n",
    "loss_ewc, acc_ewc = ewc_process(epochs, importance=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "l3GYR2WvTzdj",
    "outputId": "056ad90c-9968-41e2-a49d-18daa5fd3b32"
   },
   "outputs": [],
   "source": [
    "loss_plot(loss_ewc) , accuracy_plot(acc_ewc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "oQg1huSnUV_c",
    "outputId": "4fabf3f5-afbd-4839-a4b6-939595f1e1b4"
   },
   "outputs": [],
   "source": [
    "plt.plot(acc[0], label=\"sgd\")\n",
    "plt.plot(acc_ewc[0], label=\"ewc\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
